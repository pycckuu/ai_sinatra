<h3> Figure shows different models performance: </h3>
<p>

<img src="<%= 'models_perform.png' %>" />

<p> The ensebmle of top 5 models (OrthogonalMatchingPursuitCV, LinearRegression, Lars, Ridge, and BayesianRidge) were taken to predict the amount of bags: <p>
<img src="<%= 'ensemble.png' %>" />

<p> <h3> The resultsing metrics of the Ensemble: </h3>
<p> Mean squared error : 0.907
<p> r2 score : 0.754
<p> Median absolute error : 0.603
<p> Explained variance score : 0.754
<p> Bias : -0.224


<p>

<h3> One to one plot (you can move, zoom in/out etc.): </h3>

<%= erb :model_perform %>


<p>
<p>
For details about learning procedure, please, refer to the page describing the steps taken:

click here

<p>
In general, all algorithms underestimate the prediction of bags in the midrange values. It would be required to pick the algorithms separately and tune the parameters for the best results. Also, it is possible to introduce the "smooth correction function" to adjust overpredicted values below "3" and underpredicted values of bags above "3".


<h3> Summary table of the model performance, where the columns are <p></h3>
<h4> name, explained variance, mean squared error, median absolute error, bias, r-squared, and model score</h4>

<table class="pretty table">
  <tbody>
  <% @model_res.each do |m| %>
  <tr>
    <td><%= m[:model] %><td>
    <td><%= m[:explained_variance_score].to_s[0..4] %><td>
    <td><%= m[:mean_squared_error].to_s[0..4] %><td>
    <td><%= m[:median_absolute_error].to_s[0..4] %><td>
    <td><%= m[:pc_bias].to_s[0..4] %><td>
    <td><%= m[:r2_score].to_s[0..4] %><td>
    <td><%= m[:score].to_s[0..4] %><td>
  </tr>
  <% end %>
  </tbody>
</table>



